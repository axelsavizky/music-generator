from music21 import *
import os
import random
import numpy as np
import matplotlib.pyplot as plt
from collections import Counter
from sklearn.model_selection import train_test_split
from datetime import datetime

from keras.layers import *
from keras.models import *
from keras.callbacks import *
import keras.backend as K
from keras.models import load_model
import multiprocessing
import sys
from pebble import ProcessPool
from concurrent.futures import TimeoutError

path = "/Users/jscherman/GolandProjects/music-generator/gwern/midis/Big_Data_Set"
frequent_notes_threshold = 256

n_of_timesteps = 32
evaluation_percentage = 0.2 # 20% of the data will be used as evaluation

output_dimension = 100
kernel_size = 3
epochs = 50

len_of_predictions = 30

def read_midi_wrapper(args):
    return read_midi(*args)

def read_midi(file, current, total):
    print(f'reading: {str(current)}/{str(total)}', flush=True)
    if current == 10:
        sleep(5)
    current += 1
    notes=[]
    notes_to_parse = None

    #parsing a midi file
    try:
        midi = converter.parse(file)
    except:
        return np.array([])

    #grouping based on different instruments
    s2 = instrument.partitionByInstrument(midi)
    if not s2:
        return np.array([])
    #Looping over all the instruments
    for part in s2.parts:

        #select elements of only piano
        if 'Piano' in str(part):

            notes_to_parse = part.recurse()

            #finding whether a particular element is note or a chord
            for element in notes_to_parse[:1024]:
#                 print(f'notes to parse: {len(list(notes_to_parse))}')
                #note
                if isinstance(element, note.Note):
                    notes.append(str(element.pitch))

                #chord
                elif isinstance(element, chord.Chord):
                    notes.append('.'.join(str(n) for n in element.normalOrder))
    print(f'finish reading: {str(current)}/{str(total)}', flush=True)
    return np.array(notes)

def convert_to_midi(prediction_output, filename):

    offset = 0
    output_notes = []

    # create note and chord objects based on the values generated by the model
    for pattern in prediction_output:

        # pattern is a chord
        if ('.' in pattern) or pattern.isdigit():
            notes_in_chord = pattern.split('.')
            notes = []
            for current_note in notes_in_chord:

                cn=int(current_note)
                new_note = note.Note(cn)
                new_note.storedInstrument = instrument.Piano()
                notes.append(new_note)

            new_chord = chord.Chord(notes)
            new_chord.offset = offset
            output_notes.append(new_chord)

        # pattern is a note
        else:

            new_note = note.Note(pattern)
            new_note.offset = offset
            new_note.storedInstrument = instrument.Piano()
            output_notes.append(new_note)

        # increase offset each iteration so that notes do not stack
        offset += 1
    midi_stream = stream.Stream(output_notes)
    midi_stream.write('midi', fp=filename)

from glob import glob
from multiprocessing.dummy import Pool as ThreadPool
from multiprocess import Pool, set_start_method
import multiprocessing
import time
from functools import partial

from pebble import ProcessPool
from concurrent.futures import TimeoutError

def fibonacci(n):
    if n == 0: return 0
    elif n == 1: return 1
    else: return fibonacci(n - 1) + fibonacci(n - 2)

if __name__ == "__main__":
    TRAINING_SET_SIZE = int(sys.argv[1]) ##Â Cambiar

#     NTHREADS = 1
    NTHREADS = multiprocessing.cpu_count()

    start_time = datetime.now()
    print('starting at: ', start_time)

    files = [y for x in os.walk(path) for y in glob(os.path.join(x[0], '*.mid'))]
    print(f'#files: {str(len(files))} | #training: {TRAINING_SET_SIZE} | #threads: {str(NTHREADS)}')
    start = time.time()
    #files=[i for i in os.listdir(path) if i.endswith(".mid")]

    total = TRAINING_SET_SIZE
    current = 1
    notes_array = []
    read_midi_input = [(file, i, total) for i, file in enumerate(files[:TRAINING_SET_SIZE])]

    notes_array = []
    with ProcessPool() as pool:
        future = pool.map(read_midi_wrapper, read_midi_input, timeout=30)
        try:
            for n in future.result():
                notes_array.append(n)
        except TimeoutError:
            print ("couldn't read midi")

    print('filtering...')
    notes_array = [e for e in notes_array if e.shape[0] > 2]

    notes_array = np.array(notes_array, dtype=object)
    print('notes...')
    notes_ = [element for note_ in notes_array for element in note_]
    end = time.time()

    print(f'took {end - start} seconds')
    print(notes_array.shape[0])

    unique_notes = list(set(notes_))
    print(len(unique_notes))

    freq = dict(Counter(notes_))

    no=[count for _,count in freq.items()]

    frequent_notes = [note_ for note_, count in freq.items() if count>=frequent_notes_threshold]
    print(f'keeping {frequent_notes} notes')

    # Get the same dataset only with frequent notes
    new_music=[]

    for notes in notes_array:
        new_music.append([note for note in notes if note in frequent_notes])

    new_music = np.array(new_music, dtype=object)


    inputs = []
    outputs = []

    for notes_ in new_music:
        for i in range(0, len(notes_) - n_of_timesteps, 1):

            inputs.append(notes_[i:i + n_of_timesteps])
            outputs.append(notes_[i + n_of_timesteps])

    inputs=np.array(inputs)
    outputs=np.array(outputs)


    unique_inputs = list(set(inputs.ravel()))
    input_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_inputs))
    import pickle
    filehandler = open(sys.argv[2]+'_dict.pickle','wb')
    pickle.dump(input_note_to_int, filehandler)
    filehandler.close()


    input_seq=[]
    for input_ in inputs:
        input_seq.append([input_note_to_int[note_] for note_ in input_])

    input_seq = np.array(input_seq)


    unique_outputs = list(set(outputs))
    output_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_outputs))
    output_seq = np.array([output_note_to_int[note_] for note_ in outputs])


    input_training, input_validation, output_training, output_validation = train_test_split(input_seq,output_seq,test_size=evaluation_percentage,random_state=0)
    print(f'#input(training/validation): {len(input_training)}/{len(input_validation)}')
    print(f'#output(training/validation): {len(output_training)}/{len(output_validation)}')

    for activation_f in ['relu', 'tanh', 'sigmoid']:

        K.clear_session()
        model = Sequential()

        # activation_f = 'relu'
        # activation_f = 'sigmoid'
        # activation_f = 'tanh'

        # Parameters explanation: https://keras.io/api/layers/core_layers/embedding/
        model.add(Embedding(len(unique_inputs), output_dimension, input_length=n_of_timesteps,trainable=True))

        # Parameters explanation: https://keras.io/api/layers/convolution_layers/convolution1d/
        model.add(Conv1D(n_of_timesteps*2*2,kernel_size, padding='causal',activation=activation_f))
        model.add(Dropout(0.2))
        model.add(MaxPool1D(2))

        model.add(Conv1D(n_of_timesteps*4*2,kernel_size, activation=activation_f,dilation_rate=2,padding='causal'))
        model.add(Dropout(0.2))
        model.add(MaxPool1D(2))

        model.add(Conv1D(n_of_timesteps*8*2,kernel_size, activation=activation_f,dilation_rate=4,padding='causal'))
        model.add(Dropout(0.2))
        model.add(MaxPool1D(2))

        #model.add(Conv1D(256,5,activation=activation_f))
        model.add(GlobalMaxPool1D())

        # Parameters explanation: https://keras.io/api/layers/core_layers/dense/
        # 256 -> 512
        model.add(Dense(512, activation=activation_f))
        model.add(Dense(len(unique_outputs), activation='softmax'))

        model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')

        model_name = f'model_{sys.argv[2]}_{activation_f}'

        epochs = 50

        checkpoint = ModelCheckpoint(model_name, monitor='val_loss', mode='min', save_best_only=True,verbose=1)
        history = model.fit(np.array(input_training),np.array(output_training), batch_size=1024, epochs=epochs, validation_data=(np.array(input_validation),np.array(output_validation)),verbose=1, callbacks=[checkpoint])

        print(f'finish at {datetime.now()} (elapsed {datetime.now() - start_time})')





