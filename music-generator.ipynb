{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cccce6fe",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e692b736",
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import *\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.callbacks import *\n",
    "import keras.backend as K\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3814c8",
   "metadata": {},
   "source": [
    "# Config variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b6faacba",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"schubert/\"\n",
    "frequent_notes_threshold = 50\n",
    "\n",
    "n_of_timesteps = 32\n",
    "evaluation_percentage = 0.2 # 20% of the data will be used as evaluation\n",
    "\n",
    "output_dimension = 100\n",
    "kernel_size = 3\n",
    "epochs = 50\n",
    "\n",
    "len_of_predictions = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48933b62",
   "metadata": {},
   "source": [
    "# Aux functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddcff1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_midi(file):\n",
    "    \n",
    "    print(\"Reading: \" + file)\n",
    "    \n",
    "    notes=[]\n",
    "    notes_to_parse = None\n",
    "    \n",
    "    #parsing a midi file\n",
    "    midi = converter.parse(file)\n",
    "  \n",
    "    #grouping based on different instruments\n",
    "    s2 = instrument.partitionByInstrument(midi)\n",
    "\n",
    "    #Looping over all the instruments\n",
    "    for part in s2.parts:\n",
    "    \n",
    "        #select elements of only piano\n",
    "        if 'Piano' in str(part): \n",
    "        \n",
    "            notes_to_parse = part.recurse() \n",
    "      \n",
    "            #finding whether a particular element is note or a chord\n",
    "            for element in notes_to_parse:\n",
    "                \n",
    "                #note\n",
    "                if isinstance(element, note.Note):\n",
    "                    notes.append(str(element.pitch))\n",
    "                \n",
    "                #chord\n",
    "                elif isinstance(element, chord.Chord):\n",
    "                    notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "\n",
    "    return np.array(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "953176ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_midi(prediction_output):\n",
    "   \n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for pattern in prediction_output:\n",
    "        \n",
    "        # pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                \n",
    "                cn=int(current_note)\n",
    "                new_note = note.Note(cn)\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "                \n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "            \n",
    "        # pattern is a note\n",
    "        else:\n",
    "            \n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += 1\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    midi_stream.write('midi', fp='music.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1cb077",
   "metadata": {},
   "source": [
    "# Core code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bec38cf",
   "metadata": {},
   "source": [
    "## Read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20ae0abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: schubert/schumm-1.mid\n",
      "Reading: schubert/schumm-2.mid\n",
      "Reading: schubert/schub_d960_4.mid\n",
      "Reading: schubert/schumm-3.mid\n",
      "Reading: schubert/schub_d960_1.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/music21/midi/translate.py:785: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=5, channel=None, data=b'Copyright \\xa9 2002 by Bernd Kr\\xfcger'>; getting generic Instrument\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: schubert/schumm-6.mid\n",
      "Reading: schubert/schumm-4.mid\n",
      "Reading: schubert/schub_d960_2.mid\n",
      "Reading: schubert/schub_d960_3.mid\n",
      "Reading: schubert/schumm-5.mid\n",
      "Reading: schubert/schuim-4.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/music21/midi/translate.py:785: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=4, channel=None, data=b'Copyright \\xa9 1996 by Bernd Krueger'>; getting generic Instrument\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: schubert/schuim-1.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/music21/midi/translate.py:785: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=5, channel=None, data=b'Copyright \\xa9 2007 by Bernd Krueger'>; getting generic Instrument\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: schubert/schuim-3.mid\n",
      "Reading: schubert/schuim-2.mid\n",
      "Reading: schubert/schubert_D850_4.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/music21/midi/translate.py:785: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=5, channel=None, data=b'Copyright \\xa9 2010 by Bernd Krueger'>; getting generic Instrument\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: schubert/schubert_D935_4.mid\n",
      "Reading: schubert/schub_d760_4.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/music21/midi/translate.py:785: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=4, channel=None, data=b'Copyright \\xa9 2004 by Bernd Kr\\xfcger'>; getting generic Instrument\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: schubert/schubert_D850_1.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/music21/midi/translate.py:785: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=5, channel=None, data=b'Copyright \\xa9 2009 by Bernd Krueger'>; getting generic Instrument\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: schubert/schubert_D935_1.mid\n",
      "Reading: schubert/schub_d760_1.mid\n",
      "Reading: schubert/schubert_D850_2.mid\n",
      "Reading: schubert/schub_d760_3.mid\n",
      "Reading: schubert/schubert_D935_2.mid\n",
      "Reading: schubert/schubert_D935_3.mid\n",
      "Reading: schubert/schubert_D850_3.mid\n",
      "Reading: schubert/schub_d760_2.mid\n",
      "Reading: schubert/schu_143_2.mid\n",
      "Reading: schubert/schu_143_3.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/music21/midi/translate.py:785: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=4, channel=None, data=b'Copyright \\xa9 1999 by Bernd Kr\\xfcger'>; getting generic Instrument\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: schubert/schu_143_1.mid\n",
      "345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xy/dzytbyv51dd88zf00d9qj1100000gn/T/ipykernel_35503/2898075006.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  notes_array = np.array([read_midi(path+i) for i in files])\n"
     ]
    }
   ],
   "source": [
    "files=[i for i in os.listdir(path) if i.endswith(\".mid\")]\n",
    "\n",
    "notes_array = np.array([read_midi(path+i) for i in files], dtype=object)\n",
    "\n",
    "notes_ = [element for note_ in notes_array for element in note_]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1796d640",
   "metadata": {},
   "source": [
    "## Analyze data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b5ab96",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_notes = list(set(notes_))\n",
    "print(len(unique_notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cb3ae24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([221.,  40.,  31.,  13.,   8.,   3.,   7.,   9.,   7.,   6.]),\n",
       " array([1.0000e+00, 1.6170e+02, 3.2240e+02, 4.8310e+02, 6.4380e+02,\n",
       "        8.0450e+02, 9.6520e+02, 1.1259e+03, 1.2866e+03, 1.4473e+03,\n",
       "        1.6080e+03]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 302,
       "width": 319
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Notes frequency\n",
    "freq = dict(Counter(notes_))\n",
    "\n",
    "no=[count for _,count in freq.items()]\n",
    "\n",
    "#set the figure size\n",
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "#plot\n",
    "plt.hist(no)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29239c8b",
   "metadata": {},
   "source": [
    "## Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "69917a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequent_notes = [note_ for note_, count in freq.items() if count>=frequent_notes_threshold]\n",
    "\n",
    "# Get the same dataset only with frequent notes\n",
    "new_music=[]\n",
    "\n",
    "for notes in notes_array:\n",
    "    new_music.append([note for note in notes if note in frequent_notes])\n",
    "    \n",
    "new_music = np.array(new_music, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4798633a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "outputs = []\n",
    "\n",
    "for notes_ in new_music:\n",
    "    for i in range(0, len(notes_) - n_of_timesteps, 1):\n",
    "        \n",
    "        inputs.append(notes_[i:i + n_of_timesteps])\n",
    "        outputs.append(notes_[i + n_of_timesteps])\n",
    "        \n",
    "inputs=np.array(inputs)\n",
    "outputs=np.array(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5380cde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_inputs = list(set(inputs.ravel()))\n",
    "input_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_inputs))\n",
    "\n",
    "input_seq=[]\n",
    "for input_ in inputs:\n",
    "    input_seq.append([input_note_to_int[note_] for note_ in input_])\n",
    "    \n",
    "input_seq = np.array(input_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b99be37",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_outputs = list(set(outputs))\n",
    "output_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_outputs)) \n",
    "output_seq = np.array([output_note_to_int[note_] for note_ in outputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2b1f93",
   "metadata": {},
   "source": [
    "## Split data into training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a98d573a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_training, input_validation, output_training, output_validation = train_test_split(input_seq,output_seq,test_size=evaluation_percentage,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8c1251",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d7657314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM architecture. We will use WaveNet for now\n",
    "# def lstm():\n",
    "#   model = Sequential()\n",
    "#   model.add(LSTM(128,return_sequences=True))\n",
    "#   model.add(LSTM(128))\n",
    "#   model.add(Dense(256))\n",
    "#   model.add(Activation('relu'))\n",
    "#   model.add(Dense(n_vocab))\n",
    "#   model.add(Activation('softmax'))\n",
    "#   model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "#   return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8e1ff869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 32, 100)           18200     \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 32, 64)            19264     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 16, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 16, 128)           24704     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 8, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 8, 256)            98560     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 4, 256)            0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 182)               46774     \n",
      "=================================================================\n",
      "Total params: 273,294\n",
      "Trainable params: 273,294\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "model = Sequential()\n",
    "\n",
    "# Parameters explanation: https://keras.io/api/layers/core_layers/embedding/\n",
    "model.add(Embedding(len(unique_inputs), output_dimension, input_length=n_of_timesteps,trainable=True)) \n",
    "\n",
    "# Parameters explanation: https://keras.io/api/layers/convolution_layers/convolution1d/\n",
    "model.add(Conv1D(n_of_timesteps*2,kernel_size, padding='causal',activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "    \n",
    "model.add(Conv1D(n_of_timesteps*4,kernel_size,activation='relu',dilation_rate=2,padding='causal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "\n",
    "model.add(Conv1D(n_of_timesteps*8,kernel_size,activation='relu',dilation_rate=4,padding='causal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "          \n",
    "#model.add(Conv1D(256,5,activation='relu'))    \n",
    "model.add(GlobalMaxPool1D())\n",
    "\n",
    "# Parameters explanation: https://keras.io/api/layers/core_layers/dense/\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(len(unique_outputs), activation='softmax'))\n",
    "    \n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c2cdaa",
   "metadata": {},
   "source": [
    "## Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "583b3f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-11 18:52:06.399029: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "492/492 [==============================] - 36s 69ms/step - loss: 4.3776 - val_loss: 4.0932\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.09325, saving model to best_model.h5\n",
      "Epoch 2/50\n",
      "492/492 [==============================] - 33s 67ms/step - loss: 3.8433 - val_loss: 3.9081\n",
      "\n",
      "Epoch 00002: val_loss improved from 4.09325 to 3.90807, saving model to best_model.h5\n",
      "Epoch 3/50\n",
      "492/492 [==============================] - 36s 73ms/step - loss: 3.6757 - val_loss: 3.7833\n",
      "\n",
      "Epoch 00003: val_loss improved from 3.90807 to 3.78328, saving model to best_model.h5\n",
      "Epoch 4/50\n",
      "492/492 [==============================] - 29s 59ms/step - loss: 3.5576 - val_loss: 3.6738\n",
      "\n",
      "Epoch 00004: val_loss improved from 3.78328 to 3.67382, saving model to best_model.h5\n",
      "Epoch 5/50\n",
      "492/492 [==============================] - 29s 60ms/step - loss: 3.4763 - val_loss: 3.6402\n",
      "\n",
      "Epoch 00005: val_loss improved from 3.67382 to 3.64024, saving model to best_model.h5\n",
      "Epoch 6/50\n",
      "492/492 [==============================] - 34s 70ms/step - loss: 3.4047 - val_loss: 3.5702\n",
      "\n",
      "Epoch 00006: val_loss improved from 3.64024 to 3.57025, saving model to best_model.h5\n",
      "Epoch 7/50\n",
      "492/492 [==============================] - 41s 84ms/step - loss: 3.3422 - val_loss: 3.5293\n",
      "\n",
      "Epoch 00007: val_loss improved from 3.57025 to 3.52935, saving model to best_model.h5\n",
      "Epoch 8/50\n",
      "492/492 [==============================] - 33s 67ms/step - loss: 3.2854 - val_loss: 3.5167\n",
      "\n",
      "Epoch 00008: val_loss improved from 3.52935 to 3.51671, saving model to best_model.h5\n",
      "Epoch 9/50\n",
      "492/492 [==============================] - 39s 78ms/step - loss: 3.2368 - val_loss: 3.4731\n",
      "\n",
      "Epoch 00009: val_loss improved from 3.51671 to 3.47306, saving model to best_model.h5\n",
      "Epoch 10/50\n",
      "492/492 [==============================] - 39s 80ms/step - loss: 3.1917 - val_loss: 3.4334\n",
      "\n",
      "Epoch 00010: val_loss improved from 3.47306 to 3.43337, saving model to best_model.h5\n",
      "Epoch 11/50\n",
      "492/492 [==============================] - 33s 68ms/step - loss: 3.1512 - val_loss: 3.4327\n",
      "\n",
      "Epoch 00011: val_loss improved from 3.43337 to 3.43275, saving model to best_model.h5\n",
      "Epoch 12/50\n",
      "492/492 [==============================] - 32s 66ms/step - loss: 3.1114 - val_loss: 3.3773\n",
      "\n",
      "Epoch 00012: val_loss improved from 3.43275 to 3.37726, saving model to best_model.h5\n",
      "Epoch 13/50\n",
      "492/492 [==============================] - 36s 72ms/step - loss: 3.0772 - val_loss: 3.3669\n",
      "\n",
      "Epoch 00013: val_loss improved from 3.37726 to 3.36687, saving model to best_model.h5\n",
      "Epoch 14/50\n",
      "492/492 [==============================] - 40s 81ms/step - loss: 3.0399 - val_loss: 3.3250\n",
      "\n",
      "Epoch 00014: val_loss improved from 3.36687 to 3.32504, saving model to best_model.h5\n",
      "Epoch 15/50\n",
      "492/492 [==============================] - 38s 78ms/step - loss: 3.0138 - val_loss: 3.3143\n",
      "\n",
      "Epoch 00015: val_loss improved from 3.32504 to 3.31430, saving model to best_model.h5\n",
      "Epoch 16/50\n",
      "492/492 [==============================] - 33s 67ms/step - loss: 2.9913 - val_loss: 3.3185\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 3.31430\n",
      "Epoch 17/50\n",
      "492/492 [==============================] - 33s 67ms/step - loss: 2.9649 - val_loss: 3.2812\n",
      "\n",
      "Epoch 00017: val_loss improved from 3.31430 to 3.28118, saving model to best_model.h5\n",
      "Epoch 18/50\n",
      "492/492 [==============================] - 33s 68ms/step - loss: 2.9418 - val_loss: 3.2576\n",
      "\n",
      "Epoch 00018: val_loss improved from 3.28118 to 3.25763, saving model to best_model.h5\n",
      "Epoch 19/50\n",
      "492/492 [==============================] - 34s 69ms/step - loss: 2.9142 - val_loss: 3.2734\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 3.25763\n",
      "Epoch 20/50\n",
      "492/492 [==============================] - 33s 66ms/step - loss: 2.9009 - val_loss: 3.2521\n",
      "\n",
      "Epoch 00020: val_loss improved from 3.25763 to 3.25215, saving model to best_model.h5\n",
      "Epoch 21/50\n",
      "492/492 [==============================] - 34s 69ms/step - loss: 2.8866 - val_loss: 3.2555\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 3.25215\n",
      "Epoch 22/50\n",
      "492/492 [==============================] - 34s 68ms/step - loss: 2.8619 - val_loss: 3.2420\n",
      "\n",
      "Epoch 00022: val_loss improved from 3.25215 to 3.24198, saving model to best_model.h5\n",
      "Epoch 23/50\n",
      "492/492 [==============================] - 34s 69ms/step - loss: 2.8485 - val_loss: 3.2160\n",
      "\n",
      "Epoch 00023: val_loss improved from 3.24198 to 3.21604, saving model to best_model.h5\n",
      "Epoch 24/50\n",
      "492/492 [==============================] - 34s 70ms/step - loss: 2.8313 - val_loss: 3.2377\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 3.21604\n",
      "Epoch 25/50\n",
      "492/492 [==============================] - 33s 68ms/step - loss: 2.8160 - val_loss: 3.2243\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 3.21604\n",
      "Epoch 26/50\n",
      "492/492 [==============================] - 34s 69ms/step - loss: 2.8030 - val_loss: 3.2147\n",
      "\n",
      "Epoch 00026: val_loss improved from 3.21604 to 3.21473, saving model to best_model.h5\n",
      "Epoch 27/50\n",
      "492/492 [==============================] - 33s 68ms/step - loss: 2.7913 - val_loss: 3.2012\n",
      "\n",
      "Epoch 00027: val_loss improved from 3.21473 to 3.20123, saving model to best_model.h5\n",
      "Epoch 28/50\n",
      "492/492 [==============================] - 33s 66ms/step - loss: 2.7778 - val_loss: 3.1896\n",
      "\n",
      "Epoch 00028: val_loss improved from 3.20123 to 3.18964, saving model to best_model.h5\n",
      "Epoch 29/50\n",
      "492/492 [==============================] - 34s 68ms/step - loss: 2.7676 - val_loss: 3.1884\n",
      "\n",
      "Epoch 00029: val_loss improved from 3.18964 to 3.18840, saving model to best_model.h5\n",
      "Epoch 30/50\n",
      "492/492 [==============================] - 35s 71ms/step - loss: 2.7556 - val_loss: 3.1922\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 3.18840\n",
      "Epoch 31/50\n",
      "492/492 [==============================] - 34s 68ms/step - loss: 2.7410 - val_loss: 3.1801\n",
      "\n",
      "Epoch 00031: val_loss improved from 3.18840 to 3.18014, saving model to best_model.h5\n",
      "Epoch 32/50\n",
      "492/492 [==============================] - 33s 67ms/step - loss: 2.7320 - val_loss: 3.1886\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 3.18014\n",
      "Epoch 33/50\n",
      "492/492 [==============================] - 33s 68ms/step - loss: 2.7264 - val_loss: 3.1634\n",
      "\n",
      "Epoch 00033: val_loss improved from 3.18014 to 3.16341, saving model to best_model.h5\n",
      "Epoch 34/50\n",
      "492/492 [==============================] - 32s 66ms/step - loss: 2.7128 - val_loss: 3.1704\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 3.16341\n",
      "Epoch 35/50\n",
      "492/492 [==============================] - 34s 68ms/step - loss: 2.7051 - val_loss: 3.1699\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 3.16341\n",
      "Epoch 36/50\n",
      "492/492 [==============================] - 33s 66ms/step - loss: 2.6980 - val_loss: 3.1711\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 3.16341\n",
      "Epoch 37/50\n",
      "492/492 [==============================] - 33s 67ms/step - loss: 2.6821 - val_loss: 3.1565\n",
      "\n",
      "Epoch 00037: val_loss improved from 3.16341 to 3.15650, saving model to best_model.h5\n",
      "Epoch 38/50\n",
      "492/492 [==============================] - 33s 67ms/step - loss: 2.6770 - val_loss: 3.1552\n",
      "\n",
      "Epoch 00038: val_loss improved from 3.15650 to 3.15525, saving model to best_model.h5\n",
      "Epoch 39/50\n",
      "492/492 [==============================] - 33s 66ms/step - loss: 2.6757 - val_loss: 3.1554\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 3.15525\n",
      "Epoch 40/50\n",
      "492/492 [==============================] - 33s 66ms/step - loss: 2.6662 - val_loss: 3.1574\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 3.15525\n",
      "Epoch 41/50\n",
      "492/492 [==============================] - 34s 70ms/step - loss: 2.6629 - val_loss: 3.1562\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 3.15525\n",
      "Epoch 42/50\n",
      "492/492 [==============================] - 33s 67ms/step - loss: 2.6553 - val_loss: 3.1515\n",
      "\n",
      "Epoch 00042: val_loss improved from 3.15525 to 3.15154, saving model to best_model.h5\n",
      "Epoch 43/50\n",
      "492/492 [==============================] - 33s 67ms/step - loss: 2.6472 - val_loss: 3.1552\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 3.15154\n",
      "Epoch 44/50\n",
      "492/492 [==============================] - 35s 71ms/step - loss: 2.6410 - val_loss: 3.1400\n",
      "\n",
      "Epoch 00044: val_loss improved from 3.15154 to 3.14000, saving model to best_model.h5\n",
      "Epoch 45/50\n",
      "492/492 [==============================] - 39s 79ms/step - loss: 2.6322 - val_loss: 3.1472\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 3.14000\n",
      "Epoch 46/50\n",
      "492/492 [==============================] - 32s 65ms/step - loss: 2.6233 - val_loss: 3.1479\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 3.14000\n",
      "Epoch 47/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "492/492 [==============================] - 30s 62ms/step - loss: 2.6219 - val_loss: 3.1451\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 3.14000\n",
      "Epoch 48/50\n",
      "492/492 [==============================] - 29s 60ms/step - loss: 2.6212 - val_loss: 3.1300\n",
      "\n",
      "Epoch 00048: val_loss improved from 3.14000 to 3.12996, saving model to best_model.h5\n",
      "Epoch 49/50\n",
      "492/492 [==============================] - 29s 60ms/step - loss: 2.6079 - val_loss: 3.1339\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 3.12996\n",
      "Epoch 50/50\n",
      "492/492 [==============================] - 29s 60ms/step - loss: 2.6058 - val_loss: 3.1292\n",
      "\n",
      "Epoch 00050: val_loss improved from 3.12996 to 3.12916, saving model to best_model.h5\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True,verbose=1)\n",
    "history = model.fit(np.array(input_training),np.array(output_training), batch_size=128, epochs=epochs, validation_data=(np.array(input_validation),np.array(output_validation)),verbose=1, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ce346779",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('best_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb959ae",
   "metadata": {},
   "source": [
    "## Generate music!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "780d3d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.random.randint(0,len(input_validation)-1)\n",
    "\n",
    "random_music = input_validation[ind]\n",
    "        \n",
    "predictions=[]\n",
    "for i in range(len_of_predictions):\n",
    "\n",
    "    random_music = random_music.reshape(1,n_of_timesteps)\n",
    "\n",
    "    prob   = model.predict(random_music)[0]\n",
    "    output_pred = np.argmax(prob,axis=0)\n",
    "    predictions.append(output_pred)\n",
    "\n",
    "    random_music = np.insert(random_music[0],len(random_music[0]),output_pred)\n",
    "    random_music = random_music[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a19ab64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D5', '7.9', '7.9', '7.9', '1.7', '7.9', '1.7', '2.6', '2.6', '2.7', '7.11', '7.11', '7.11', '7.11', '7.11', '7.11', '7.11', '2.7', '7.11', '2.7', '7.11', '7.11', '2.7', '7.11', '7.11', '2.7', '7.11', '7.11', '7.11', '7.11']\n"
     ]
    }
   ],
   "source": [
    "input_int_to_note = dict((number, note_) for number, note_ in enumerate(unique_inputs)) \n",
    "predicted_notes = [input_int_to_note[i] for i in predictions]\n",
    "print(predicted_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5bce8fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_midi(predicted_notes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
